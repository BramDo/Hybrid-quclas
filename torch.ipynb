{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b052c7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.3 (main, Jun 18 2025, 17:59:45) [GCC 13.3.0] Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
      "ok 2.3.2 1.4.3\n"
     ]
    }
   ],
   "source": [
    "import sys, platform; print(sys.version, platform.platform())\n",
    "import numpy, qiskit, qiskit_aer\n",
    "print(\"ok\", numpy.__version__, qiskit.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d123c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n",
      "/home/bram/.venvs/qistorch/lib/python3.12/site-packages/qiskit_machine_learning/connectors/torch_connector.py:378: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._weights.data = torch.tensor(initial_weights, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  50 | loss 0.0004 | θ=[-0.22695376]\n",
      "epoch 100 | loss 0.0003 | θ=[-0.21039987]\n",
      "epoch 150 | loss 0.0002 | θ=[-0.19699024]\n",
      "epoch 200 | loss 0.0002 | θ=[-0.18298464]\n",
      "features [<Z>, <X>] at x=0.7: [[0.7598122  0.62744886]] | prediction: [[0.6076802]]\n"
     ]
    }
   ],
   "source": [
    "# pip install 'qiskit>=1.4' 'qiskit-machine-learning>=0.8' 'torch>=2.2' qiskit-aer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import StatevectorEstimator  # exact expectation values\n",
    "\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "\n",
    "# Reproducibility\n",
    "algorithm_globals.random_seed = 7\n",
    "torch.manual_seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "# --- Quantum front end: U(θ;x) = RY(x) ▷ RZ(θ) on |0> ---\n",
    "x = Parameter(\"x\")          # data input\n",
    "theta = Parameter(\"θ\")      # trainable weight\n",
    "\n",
    "qc = QuantumCircuit(1, name=\"U(θ;x)\")\n",
    "qc.ry(x, 0)\n",
    "qc.rz(theta, 0)\n",
    "\n",
    "# Observables to read out -> 2-D feature vector [<Z>, <X>]\n",
    "Z = SparsePauliOp.from_list([(\"Z\", 1.0)])\n",
    "X = SparsePauliOp.from_list([(\"X\", 1.0)])\n",
    "\n",
    "estimator = StatevectorEstimator()\n",
    "\n",
    "qnn = EstimatorQNN(\n",
    "    circuit=qc,\n",
    "    observables=[Z, X],          # multi-output\n",
    "    input_params=[x],            # bind classical input here\n",
    "    weight_params=[theta],       # θ is trainable\n",
    "    estimator=estimator,\n",
    "    # input_gradients=False      # set True only if you also want d/dx\n",
    ")\n",
    "\n",
    "# Make it a PyTorch layer with trainable θ\n",
    "q_layer = TorchConnector(qnn, initial_weights=torch.tensor([0.1], dtype=torch.float32))\n",
    "\n",
    "# --- Classical head: 2 -> 16 -> 1 MLP ---\n",
    "class Hybrid(nn.Module):\n",
    "    def __init__(self, q_layer):\n",
    "        super().__init__()\n",
    "        self.q_layer = q_layer\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "    def forward(self, x_batch):\n",
    "        # Expect shape [batch, 1] for the single scalar input x\n",
    "        if x_batch.ndim == 1:\n",
    "            x_batch = x_batch.view(-1, 1)\n",
    "        feats = self.q_layer(x_batch)        # -> [batch, 2] = [<Z>, <X>]\n",
    "        return self.mlp(feats)\n",
    "\n",
    "model = Hybrid(q_layer)\n",
    "\n",
    "# --- Tiny toy task (regression): learn y = sin(x) on x ∈ [-π, π] ---\n",
    "N = 64\n",
    "X_train = (2 * np.pi) * torch.rand(N, 1, dtype=torch.float32) - np.pi\n",
    "y_train = torch.sin(X_train)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=0.05)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    opt.zero_grad()\n",
    "    pred = model(X_train)\n",
    "    loss = loss_fn(pred, y_train)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"epoch {epoch+1:3d} | loss {loss.item():.4f} | θ={model.q_layer.weight.detach().cpu().numpy()}\")\n",
    "\n",
    "# Inspect the quantum features and the prediction for one point\n",
    "x_test = torch.tensor([[0.7]], dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    feats = model.q_layer(x_test)         # [<Z>, <X>]\n",
    "    yhat = model(x_test)\n",
    "print(\"features [<Z>, <X>] at x=0.7:\", feats.numpy(), \"| prediction:\", yhat.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qistorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
